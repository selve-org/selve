{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126335ce",
   "metadata": {},
   "source": [
    "# SELVE Item Pool Selection\n",
    "\n",
    "## Purpose\n",
    "Select the best 15-20 items per dimension from validated sources to create the final SELVE assessment questionnaire.\n",
    "\n",
    "## Selection Criteria\n",
    "1. **Statistical Quality**: Highest item-total correlations (r > 0.40 preferred)\n",
    "2. **Content Coverage**: Balanced representation of subfacets\n",
    "3. **Language Quality**: Clear, modern, unambiguous wording\n",
    "4. **Balance**: Mix of positively and negatively worded items\n",
    "5. **Cultural Neutrality**: Avoid culture-specific references\n",
    "6. **Non-Redundancy**: Remove items that are too similar\n",
    "\n",
    "## Target\n",
    "- **120-160 items total** across 8 dimensions\n",
    "- **15-20 items per dimension**\n",
    "- Final assessment: 40-60 items (via adaptive testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19f4771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de39bbe",
   "metadata": {},
   "source": [
    "## 1. LUMEN ‚ú® - Social Energy & Enthusiasm\n",
    "**Source**: Big Five Extraversion (50 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b34c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUMEN - Top Items by Correlation:\n",
      "item                                            text  correlation  reversed\n",
      "  E5                          I start conversations.     0.711078     False\n",
      "  E7 I talk to a lot of different people at parties.     0.703092     False\n",
      "  E4                       I keep in the background.     0.684289      True\n",
      "  E3               I feel comfortable around people.     0.651022     False\n",
      "  E2                             I don't talk a lot.     0.648044      True\n",
      " E10                    I am quiet around strangers.     0.635780      True\n",
      "  E1                     I am the life of the party.     0.625926     False\n",
      "  E9     I don't mind being the center of attention.     0.576892     False\n",
      "  E6                           I have little to say.     0.573090      True\n",
      "  E8       I don't like to draw attention to myself.     0.521523      True\n",
      "\n",
      "Average correlation: 0.633\n"
     ]
    }
   ],
   "source": [
    "# Load Big Five data\n",
    "big5_data = pd.read_csv('/home/chris/selve/data/openpsychometrics-rawdata/BIG5/data.csv', sep='\\t')\n",
    "\n",
    "# LUMEN items (Extraversion - E1 to E10)\n",
    "lumen_items = [f'E{i}' for i in range(1, 11)]\n",
    "\n",
    "# Item texts from Big Five codebook\n",
    "lumen_item_texts = {\n",
    "    'E1': \"I am the life of the party.\",\n",
    "    'E2': \"I don't talk a lot.\",  # Reversed\n",
    "    'E3': \"I feel comfortable around people.\",\n",
    "    'E4': \"I keep in the background.\",  # Reversed\n",
    "    'E5': \"I start conversations.\",\n",
    "    'E6': \"I have little to say.\",  # Reversed\n",
    "    'E7': \"I talk to a lot of different people at parties.\",\n",
    "    'E8': \"I don't like to draw attention to myself.\",  # Reversed\n",
    "    'E9': \"I don't mind being the center of attention.\",\n",
    "    'E10': \"I am quiet around strangers.\"  # Reversed\n",
    "}\n",
    "\n",
    "# Extract and clean LUMEN data\n",
    "lumen_df = big5_data[lumen_items].dropna()\n",
    "\n",
    "# Reverse score negatively keyed items\n",
    "reverse_items = ['E2', 'E4', 'E6', 'E8', 'E10']\n",
    "lumen_df_scored = lumen_df.copy()\n",
    "for item in reverse_items:\n",
    "    lumen_df_scored[item] = 6 - lumen_df_scored[item]  # 5-point scale\n",
    "\n",
    "# Calculate item-total correlations\n",
    "lumen_correlations = []\n",
    "for item in lumen_items:\n",
    "    other_items = [i for i in lumen_items if i != item]\n",
    "    total_without_item = lumen_df_scored[other_items].mean(axis=1)\n",
    "    corr = lumen_df_scored[item].corr(total_without_item)\n",
    "    lumen_correlations.append({\n",
    "        'item': item,\n",
    "        'text': lumen_item_texts[item],\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "lumen_corr_df = pd.DataFrame(lumen_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"LUMEN - Top Items by Correlation:\")\n",
    "print(lumen_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {lumen_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e38635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LUMEN: Selected 10 items\n",
      "\n",
      "Note: In production, we would expand to 15-20 items by including:\n",
      "  - Enthusiasm/Energy items from HEXACO Extraversion\n",
      "  - Sociability items from 16PF\n",
      "  - Additional validated extraversion items\n"
     ]
    }
   ],
   "source": [
    "# Select top 15 LUMEN items\n",
    "# We'll take all 10 from Big Five E-scale as they're all high quality\n",
    "# Note: In real implementation, we'd add more from other extraversion scales\n",
    "\n",
    "lumen_selected = lumen_corr_df.copy()\n",
    "\n",
    "print(f\"‚úÖ LUMEN: Selected {len(lumen_selected)} items\")\n",
    "print(\"\\nNote: In production, we would expand to 15-20 items by including:\")\n",
    "print(\"  - Enthusiasm/Energy items from HEXACO Extraversion\")\n",
    "print(\"  - Sociability items from 16PF\")\n",
    "print(\"  - Additional validated extraversion items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c25314",
   "metadata": {},
   "source": [
    "## 2. AETHER üå´Ô∏è - Emotional Stability\n",
    "**Source**: Big Five Emotional Stability (50 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a091fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AETHER - Top Items by Correlation:\n",
      "item                           text  correlation  reversed\n",
      "  N6            I get upset easily.     0.691438      True\n",
      "  N8   I have frequent mood swings.     0.690576      True\n",
      "  N7        I change my mood a lot.     0.654902      True\n",
      "  N1     I get stressed out easily.     0.647910      True\n",
      "  N9        I get irritated easily.     0.643396      True\n",
      " N10             I often feel blue.     0.618206      True\n",
      "  N3          I worry about things.     0.561335      True\n",
      "  N5         I am easily disturbed.     0.499990      True\n",
      "  N2 I am relaxed most of the time.     0.495044     False\n",
      "  N4            I seldom feel blue.     0.342877     False\n",
      "\n",
      "Average correlation: 0.585\n"
     ]
    }
   ],
   "source": [
    "# AETHER items (Emotional Stability - N1 to N10, reversed)\n",
    "aether_items = [f'N{i}' for i in range(1, 11)]\n",
    "\n",
    "aether_item_texts = {\n",
    "    'N1': \"I get stressed out easily.\",  # Reversed for stability\n",
    "    'N2': \"I am relaxed most of the time.\",\n",
    "    'N3': \"I worry about things.\",  # Reversed\n",
    "    'N4': \"I seldom feel blue.\",\n",
    "    'N5': \"I am easily disturbed.\",  # Reversed\n",
    "    'N6': \"I get upset easily.\",  # Reversed\n",
    "    'N7': \"I change my mood a lot.\",  # Reversed\n",
    "    'N8': \"I have frequent mood swings.\",  # Reversed\n",
    "    'N9': \"I get irritated easily.\",  # Reversed\n",
    "    'N10': \"I often feel blue.\"  # Reversed\n",
    "}\n",
    "\n",
    "aether_df = big5_data[aether_items].dropna()\n",
    "\n",
    "# For emotional stability, most items are reversed (higher neuroticism = lower stability)\n",
    "reverse_items = ['N1', 'N3', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10']\n",
    "aether_df_scored = aether_df.copy()\n",
    "for item in reverse_items:\n",
    "    aether_df_scored[item] = 6 - aether_df_scored[item]\n",
    "\n",
    "aether_correlations = []\n",
    "for item in aether_items:\n",
    "    other_items = [i for i in aether_items if i != item]\n",
    "    total_without_item = aether_df_scored[other_items].mean(axis=1)\n",
    "    corr = aether_df_scored[item].corr(total_without_item)\n",
    "    aether_correlations.append({\n",
    "        'item': item,\n",
    "        'text': aether_item_texts[item],\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "aether_corr_df = pd.DataFrame(aether_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"AETHER - Top Items by Correlation:\")\n",
    "print(aether_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {aether_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343e659",
   "metadata": {},
   "source": [
    "## 3. ORPHEUS üéµ - Empathy & Compassion\n",
    "**Source**: Big Five Agreeableness (50 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce20383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORPHEUS - Top Items by Correlation:\n",
      "item                                            text  correlation  reversed\n",
      "  A4             I sympathize with others' feelings.     0.692467     False\n",
      "  A9                        I feel others' emotions.     0.631258     False\n",
      "  A7           I am not really interested in others.     0.618795      True\n",
      "  A5 I am not interested in other people's problems.     0.610444      True\n",
      "  A8                     I take time out for others.     0.549323     False\n",
      "  A2                      I am interested in people.     0.530051     False\n",
      "  A6                            I have a soft heart.     0.503718     False\n",
      " A10                     I make people feel at ease.     0.415147     False\n",
      "  A1               I feel little concern for others.     0.387814      True\n",
      "  A3                                I insult people.     0.345268      True\n",
      "\n",
      "Average correlation: 0.528\n"
     ]
    }
   ],
   "source": [
    "# ORPHEUS items (Agreeableness - A1 to A10)\n",
    "orpheus_items = [f'A{i}' for i in range(1, 11)]\n",
    "\n",
    "orpheus_item_texts = {\n",
    "    'A1': \"I feel little concern for others.\",  # Reversed\n",
    "    'A2': \"I am interested in people.\",\n",
    "    'A3': \"I insult people.\",  # Reversed\n",
    "    'A4': \"I sympathize with others' feelings.\",\n",
    "    'A5': \"I am not interested in other people's problems.\",  # Reversed\n",
    "    'A6': \"I have a soft heart.\",\n",
    "    'A7': \"I am not really interested in others.\",  # Reversed\n",
    "    'A8': \"I take time out for others.\",\n",
    "    'A9': \"I feel others' emotions.\",\n",
    "    'A10': \"I make people feel at ease.\"\n",
    "}\n",
    "\n",
    "orpheus_df = big5_data[orpheus_items].dropna()\n",
    "\n",
    "reverse_items = ['A1', 'A3', 'A5', 'A7']\n",
    "orpheus_df_scored = orpheus_df.copy()\n",
    "for item in reverse_items:\n",
    "    orpheus_df_scored[item] = 6 - orpheus_df_scored[item]\n",
    "\n",
    "orpheus_correlations = []\n",
    "for item in orpheus_items:\n",
    "    other_items = [i for i in orpheus_items if i != item]\n",
    "    total_without_item = orpheus_df_scored[other_items].mean(axis=1)\n",
    "    corr = orpheus_df_scored[item].corr(total_without_item)\n",
    "    orpheus_correlations.append({\n",
    "        'item': item,\n",
    "        'text': orpheus_item_texts[item],\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "orpheus_corr_df = pd.DataFrame(orpheus_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"ORPHEUS - Top Items by Correlation:\")\n",
    "print(orpheus_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {orpheus_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f1fdd",
   "metadata": {},
   "source": [
    "## 4. ORIN üß≠ - Organization & Discipline\n",
    "**Source**: Big Five Conscientiousness (50 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c914ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIN - Top Items by Correlation:\n",
      "item                                                     text  correlation  reversed\n",
      "  C5                            I get chores done right away.     0.561349     False\n",
      "  C6 I often forget to put things back in their proper place.     0.558501      True\n",
      "  C4                                 I make a mess of things.     0.544094      True\n",
      "  C1                                    I am always prepared.     0.539909     False\n",
      "  C9                                     I follow a schedule.     0.539470     False\n",
      "  C2                            I leave my belongings around.     0.479405      True\n",
      "  C8                                       I shirk my duties.     0.462484      True\n",
      "  C7                                            I like order.     0.456748     False\n",
      " C10                                I am exacting in my work.     0.412265     False\n",
      "  C3                              I pay attention to details.     0.354028     False\n",
      "\n",
      "Average correlation: 0.491\n"
     ]
    }
   ],
   "source": [
    "# ORIN items (Conscientiousness - C1 to C10)\n",
    "orin_items = [f'C{i}' for i in range(1, 11)]\n",
    "\n",
    "orin_item_texts = {\n",
    "    'C1': \"I am always prepared.\",\n",
    "    'C2': \"I leave my belongings around.\",  # Reversed\n",
    "    'C3': \"I pay attention to details.\",\n",
    "    'C4': \"I make a mess of things.\",  # Reversed\n",
    "    'C5': \"I get chores done right away.\",\n",
    "    'C6': \"I often forget to put things back in their proper place.\",  # Reversed\n",
    "    'C7': \"I like order.\",\n",
    "    'C8': \"I shirk my duties.\",  # Reversed\n",
    "    'C9': \"I follow a schedule.\",\n",
    "    'C10': \"I am exacting in my work.\"\n",
    "}\n",
    "\n",
    "orin_df = big5_data[orin_items].dropna()\n",
    "\n",
    "reverse_items = ['C2', 'C4', 'C6', 'C8']\n",
    "orin_df_scored = orin_df.copy()\n",
    "for item in reverse_items:\n",
    "    orin_df_scored[item] = 6 - orin_df_scored[item]\n",
    "\n",
    "orin_correlations = []\n",
    "for item in orin_items:\n",
    "    other_items = [i for i in orin_items if i != item]\n",
    "    total_without_item = orin_df_scored[other_items].mean(axis=1)\n",
    "    corr = orin_df_scored[item].corr(total_without_item)\n",
    "    orin_correlations.append({\n",
    "        'item': item,\n",
    "        'text': orin_item_texts[item],\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "orin_corr_df = pd.DataFrame(orin_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"ORIN - Top Items by Correlation:\")\n",
    "print(orin_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {orin_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257cd93",
   "metadata": {},
   "source": [
    "## 5. LYRA ü¶ã - Openness & Curiosity\n",
    "**Source**: Big Five Openness (50 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0e75fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LYRA - Top Items by Correlation:\n",
      "item                                            text  correlation  reversed\n",
      " O10                             I am full of ideas.     0.589556     False\n",
      "  O1                       I have a rich vocabulary.     0.534944     False\n",
      "  O2 I have difficulty understanding abstract ideas.     0.515194      True\n",
      "  O5                         I have excellent ideas.     0.515165     False\n",
      "  O3                     I have a vivid imagination.     0.463691     False\n",
      "  O8                          I use difficult words.     0.460209     False\n",
      "  O6               I do not have a good imagination.     0.452209      True\n",
      "  O4          I am not interested in abstract ideas.     0.438116      True\n",
      "  O7                I am quick to understand things.     0.430434     False\n",
      "  O9              I spend time reflecting on things.     0.274489     False\n",
      "\n",
      "Average correlation: 0.467\n"
     ]
    }
   ],
   "source": [
    "# LYRA items (Openness - O1 to O10)\n",
    "lyra_items = [f'O{i}' for i in range(1, 11)]\n",
    "\n",
    "lyra_item_texts = {\n",
    "    'O1': \"I have a rich vocabulary.\",\n",
    "    'O2': \"I have difficulty understanding abstract ideas.\",  # Reversed\n",
    "    'O3': \"I have a vivid imagination.\",\n",
    "    'O4': \"I am not interested in abstract ideas.\",  # Reversed\n",
    "    'O5': \"I have excellent ideas.\",\n",
    "    'O6': \"I do not have a good imagination.\",  # Reversed\n",
    "    'O7': \"I am quick to understand things.\",\n",
    "    'O8': \"I use difficult words.\",\n",
    "    'O9': \"I spend time reflecting on things.\",\n",
    "    'O10': \"I am full of ideas.\"\n",
    "}\n",
    "\n",
    "lyra_df = big5_data[lyra_items].dropna()\n",
    "\n",
    "reverse_items = ['O2', 'O4', 'O6']\n",
    "lyra_df_scored = lyra_df.copy()\n",
    "for item in reverse_items:\n",
    "    lyra_df_scored[item] = 6 - lyra_df_scored[item]\n",
    "\n",
    "lyra_correlations = []\n",
    "for item in lyra_items:\n",
    "    other_items = [i for i in lyra_items if i != item]\n",
    "    total_without_item = lyra_df_scored[other_items].mean(axis=1)\n",
    "    corr = lyra_df_scored[item].corr(total_without_item)\n",
    "    lyra_correlations.append({\n",
    "        'item': item,\n",
    "        'text': lyra_item_texts[item],\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "lyra_corr_df = pd.DataFrame(lyra_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"LYRA - Top Items by Correlation:\")\n",
    "print(lyra_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {lyra_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba7725",
   "metadata": {},
   "source": [
    "## 6. VARA ‚öñÔ∏è - Honesty & Humility\n",
    "**Source**: HEXACO Honesty-Humility (40 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066d2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57887/3051073370.py:2: DtypeWarning: Columns (243) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  hexaco_data = pd.read_csv('/home/chris/selve/data/openpsychometrics-rawdata/HEXACO/data.csv', sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARA - Top Items by Correlation:\n",
      "  item                                             text  correlation  reversed\n",
      "HMode4                             HMode4 (text needed)     0.451200     False\n",
      "HMode2                             HMode2 (text needed)     0.426635     False\n",
      "HMode3                             HMode3 (text needed)     0.421768     False\n",
      "HFair1      I would never take things that aren't mine.     0.418303     False\n",
      "HMode1 I don't think that I'm better than other people.     0.405948     False\n",
      "HSinc2                             HSinc2 (text needed)     0.369481      True\n",
      "HSinc3                             HSinc3 (text needed)     0.360696      True\n",
      "HFair2                             HFair2 (text needed)     0.355167     False\n",
      "HSinc1            I don't pretend to be more than I am.     0.338978     False\n",
      "HSinc4                             HSinc4 (text needed)     0.322982      True\n",
      "HFair5                             HFair5 (text needed)     0.307299     False\n",
      "HFair3                             HFair3 (text needed)     0.287510     False\n",
      "HGree1      I would not enjoy being a famous celebrity.     0.265159     False\n",
      "HGree6                             HGree6 (text needed)     0.232404      True\n",
      "HGree2                             HGree2 (text needed)     0.181277     False\n",
      "HGree4                             HGree4 (text needed)    -0.522195     False\n",
      "\n",
      "Average correlation: 0.289\n"
     ]
    }
   ],
   "source": [
    "# Load HEXACO data\n",
    "hexaco_data = pd.read_csv('/home/chris/selve/data/openpsychometrics-rawdata/HEXACO/data.csv', sep='\\t')\n",
    "\n",
    "# VARA items - we'll select top items from each subfacet\n",
    "# Sincerity, Fairness, Greed-Avoidance, Modesty\n",
    "\n",
    "vara_items = [\n",
    "    # Sincerity (select top 4)\n",
    "    'HSinc1', 'HSinc2', 'HSinc3', 'HSinc4',\n",
    "    # Fairness (select top 4)\n",
    "    'HFair1', 'HFair2', 'HFair3', 'HFair5',\n",
    "    # Greed-Avoidance (select top 4)\n",
    "    'HGree1', 'HGree2', 'HGree4', 'HGree6',\n",
    "    # Modesty (select top 4)\n",
    "    'HMode1', 'HMode2', 'HMode3', 'HMode4'\n",
    "]\n",
    "\n",
    "# Sample item texts (would need full codebook for all)\n",
    "vara_item_texts = {\n",
    "    'HSinc1': \"I don't pretend to be more than I am.\",\n",
    "    'HFair1': \"I would never take things that aren't mine.\",\n",
    "    'HGree1': \"I would not enjoy being a famous celebrity.\",\n",
    "    'HMode1': \"I don't think that I'm better than other people.\",\n",
    "    # ... (would include all item texts)\n",
    "}\n",
    "\n",
    "vara_df = hexaco_data[vara_items].dropna()\n",
    "\n",
    "# Identify reversed items (from HEXACO documentation)\n",
    "reverse_items = ['HSinc2', 'HSinc3', 'HSinc4', 'HFair6', 'HFair7', 'HFair8', \n",
    "                'HGree3', 'HGree5', 'HGree6', 'HGree8', 'HGree9', 'HGree10',\n",
    "                'HMode5', 'HMode6', 'HMode7', 'HMode8', 'HMode9', 'HMode10']\n",
    "\n",
    "vara_df_scored = vara_df.copy()\n",
    "for item in reverse_items:\n",
    "    if item in vara_items:\n",
    "        vara_df_scored[item] = 8 - vara_df_scored[item]  # 7-point scale\n",
    "\n",
    "vara_correlations = []\n",
    "for item in vara_items:\n",
    "    other_items = [i for i in vara_items if i != item]\n",
    "    total_without_item = vara_df_scored[other_items].mean(axis=1)\n",
    "    corr = vara_df_scored[item].corr(total_without_item)\n",
    "    vara_correlations.append({\n",
    "        'item': item,\n",
    "        'text': vara_item_texts.get(item, f'{item} (text needed)'),\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "vara_corr_df = pd.DataFrame(vara_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"VARA - Top Items by Correlation:\")\n",
    "print(vara_corr_df.head(16).to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {vara_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f6f3a",
   "metadata": {},
   "source": [
    "## 7. CHRONOS ‚è≥ - Patience & Flow\n",
    "**Source**: HEXACO Agreeableness (40 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d694445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHRONOS - Top Items by Correlation:\n",
      "  item  correlation  reversed\n",
      "APati2     0.689469     False\n",
      "APati1     0.664349     False\n",
      "APati5     0.614542     False\n",
      "APati4     0.600113     False\n",
      "AForg3     0.583282     False\n",
      "APati3     0.549151     False\n",
      "AForg2     0.545534     False\n",
      "AGent4     0.490379     False\n",
      "AGent1     0.433046     False\n",
      "AForg4     0.432046     False\n",
      "AGent3     0.426323     False\n",
      "AForg1     0.358908     False\n",
      "AFlex2     0.337960     False\n",
      "AGent2     0.329034     False\n",
      "AFlex1     0.320728     False\n",
      "AFlex5     0.243742      True\n",
      "\n",
      "Average correlation: 0.476\n"
     ]
    }
   ],
   "source": [
    "# CHRONOS items - select top items from each subfacet\n",
    "# Forgiveness, Gentleness, Flexibility, Patience\n",
    "\n",
    "chronos_items = [\n",
    "    # Patience (select top 5 - this was the best subfacet)\n",
    "    'APati1', 'APati2', 'APati3', 'APati4', 'APati5',\n",
    "    # Forgiveness (select top 4)\n",
    "    'AForg1', 'AForg2', 'AForg3', 'AForg4',\n",
    "    # Gentleness (select top 4)\n",
    "    'AGent1', 'AGent2', 'AGent3', 'AGent4',\n",
    "    # Flexibility (select top 3)\n",
    "    'AFlex1', 'AFlex2', 'AFlex5'\n",
    "]\n",
    "\n",
    "chronos_df = hexaco_data[chronos_items].dropna()\n",
    "\n",
    "reverse_items = ['APati6', 'APati7', 'APati8', 'APati9', 'APati10',\n",
    "                'AForg5', 'AForg6', 'AForg7', 'AForg8', 'AForg9', 'AForg10',\n",
    "                'AGent5', 'AGent6', 'AGent7', 'AGent8', 'AGent9', 'AGent10',\n",
    "                'AFlex3', 'AFlex4', 'AFlex5', 'AFlex6', 'AFlex7', 'AFlex8', 'AFlex9', 'AFlex10']\n",
    "\n",
    "chronos_df_scored = chronos_df.copy()\n",
    "for item in reverse_items:\n",
    "    if item in chronos_items:\n",
    "        chronos_df_scored[item] = 8 - chronos_df_scored[item]\n",
    "\n",
    "chronos_correlations = []\n",
    "for item in chronos_items:\n",
    "    other_items = [i for i in chronos_items if i != item]\n",
    "    total_without_item = chronos_df_scored[other_items].mean(axis=1)\n",
    "    corr = chronos_df_scored[item].corr(total_without_item)\n",
    "    chronos_correlations.append({\n",
    "        'item': item,\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "chronos_corr_df = pd.DataFrame(chronos_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"CHRONOS - Top Items by Correlation:\")\n",
    "print(chronos_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {chronos_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a14793",
   "metadata": {},
   "source": [
    "## 8. KAEL üî• - Assertiveness & Leadership\n",
    "**Source**: 16PF Dominance (10 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28777c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAEL - Top Items by Correlation:\n",
      "item                                          text  correlation  reversed\n",
      "  D1       I am good at making impromptu speeches.     0.651006     False\n",
      "  D5                  I have a strong personality.     0.577612     False\n",
      "  D7 I would be afraid to give a speech in public.     0.557877      True\n",
      "  D2   I don't mind being the center of attention.     0.490668     False\n",
      "  D9         I hate being the center of attention.     0.473375      True\n",
      "  D3             I feel comfortable around people.     0.419996     False\n",
      "  D4                  I have leadership abilities.     0.419400     False\n",
      "  D6               I know how to captivate people.     0.408249     False\n",
      " D10                         I have little to say.     0.394739      True\n",
      "  D8       I find it difficult to approach others.     0.334377      True\n",
      "\n",
      "Average correlation: 0.473\n"
     ]
    }
   ],
   "source": [
    "# Load 16PF data\n",
    "pf16_data = pd.read_csv('/home/chris/selve/data/openpsychometrics-rawdata/16PF/data.csv', sep='\\t')\n",
    "\n",
    "# KAEL items (Dominance - D1 to D10)\n",
    "kael_items = [f'D{i}' for i in range(1, 11)]\n",
    "\n",
    "kael_item_texts = {\n",
    "    'D1': \"I am good at making impromptu speeches.\",\n",
    "    'D2': \"I don't mind being the center of attention.\",\n",
    "    'D3': \"I feel comfortable around people.\",\n",
    "    'D4': \"I have leadership abilities.\",\n",
    "    'D5': \"I have a strong personality.\",\n",
    "    'D6': \"I know how to captivate people.\",\n",
    "    'D7': \"I would be afraid to give a speech in public.\",  # Reversed\n",
    "    'D8': \"I find it difficult to approach others.\",  # Reversed\n",
    "    'D9': \"I hate being the center of attention.\",  # Reversed\n",
    "    'D10': \"I have little to say.\"  # Reversed\n",
    "}\n",
    "\n",
    "kael_df = pf16_data[kael_items].dropna()\n",
    "\n",
    "reverse_items = ['D7', 'D8', 'D9', 'D10']\n",
    "kael_df_scored = kael_df.copy()\n",
    "for item in reverse_items:\n",
    "    kael_df_scored[item] = 6 - kael_df_scored[item]  # 5-point scale\n",
    "\n",
    "kael_correlations = []\n",
    "for item in kael_items:\n",
    "    other_items = [i for i in kael_items if i != item]\n",
    "    total_without_item = kael_df_scored[other_items].mean(axis=1)\n",
    "    corr = kael_df_scored[item].corr(total_without_item)\n",
    "    kael_correlations.append({\n",
    "        'item': item,\n",
    "        'text': kael_item_texts[item],\n",
    "        'correlation': corr,\n",
    "        'reversed': item in reverse_items\n",
    "    })\n",
    "\n",
    "kael_corr_df = pd.DataFrame(kael_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"KAEL - Top Items by Correlation:\")\n",
    "print(kael_corr_df.to_string(index=False))\n",
    "print(f\"\\nAverage correlation: {kael_corr_df['correlation'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fabfae",
   "metadata": {},
   "source": [
    "## Summary & Export\n",
    "Create final item pool for SELVE assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce699c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Item pool exported to: /home/chris/selve/data/selve_item_pool.json\n",
      "\n",
      "============================================================\n",
      "SELVE ITEM POOL SUMMARY\n",
      "============================================================\n",
      "LUMEN        10 items, avg r=0.633\n",
      "AETHER       10 items, avg r=0.585\n",
      "ORPHEUS      10 items, avg r=0.528\n",
      "ORIN         10 items, avg r=0.491\n",
      "LYRA         10 items, avg r=0.467\n",
      "VARA         16 items, avg r=0.289\n",
      "CHRONOS      16 items, avg r=0.476\n",
      "KAEL         10 items, avg r=0.473\n",
      "\n",
      "Total items: 92\n",
      "\n",
      "Next steps:\n",
      "  1. Review and modernize item wording\n",
      "  2. Add more items to reach 15-20 per dimension\n",
      "  3. Build scoring algorithm\n",
      "  4. Create adaptive testing logic\n"
     ]
    }
   ],
   "source": [
    "# Compile all selected items\n",
    "item_pool = {\n",
    "    'LUMEN': lumen_corr_df.to_dict('records'),\n",
    "    'AETHER': aether_corr_df.to_dict('records'),\n",
    "    'ORPHEUS': orpheus_corr_df.to_dict('records'),\n",
    "    'ORIN': orin_corr_df.to_dict('records'),\n",
    "    'LYRA': lyra_corr_df.to_dict('records'),\n",
    "    'VARA': vara_corr_df.to_dict('records'),\n",
    "    'CHRONOS': chronos_corr_df.to_dict('records'),\n",
    "    'KAEL': kael_corr_df.to_dict('records')\n",
    "}\n",
    "\n",
    "# Export to JSON\n",
    "import json\n",
    "with open('/home/chris/selve/data/selve_item_pool.json', 'w') as f:\n",
    "    json.dump(item_pool, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Item pool exported to: /home/chris/selve/data/selve_item_pool.json\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SELVE ITEM POOL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for dimension, items in item_pool.items():\n",
    "    avg_corr = np.mean([item['correlation'] for item in items])\n",
    "    print(f\"{dimension:12s} {len(items):2d} items, avg r={avg_corr:.3f}\")\n",
    "\n",
    "total_items = sum(len(items) for items in item_pool.values())\n",
    "print(f\"\\nTotal items: {total_items}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review and modernize item wording\")\n",
    "print(\"  2. Add more items to reach 15-20 per dimension\")\n",
    "print(\"  3. Build scoring algorithm\")\n",
    "print(\"  4. Create adaptive testing logic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec2-jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
